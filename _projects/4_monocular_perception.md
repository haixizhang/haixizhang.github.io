---
layout: page
title: Monocular Real-time Perception for Autonomous Driving
description: Unified perception pipeline with object tracking and depth estimation
img: assets/img/7.jpg
importance: 4
category: research
---
## Project Overview
Development of a unified monocular perception pipeline for autonomous driving applications, integrating multiple computer vision tasks in a real-time system.

## Technical Implementation
- **Framework**: PyTorch
- **Language**: Python
- **Performance**: 30+ FPS on single GPU
- **Duration**: April 2023 â€“ August 2023

## Key Features
- **Multi-task Integration**: Object tracking, trajectory prediction, road segmentation, and depth estimation
- **Real-time Performance**: Achieved 30+ FPS on a single GPU
- **Optimized Architecture**: Shared Transformer backbones with lightweight decoders
- **Publication Status**: Under review at IEEE RA-L

## Technical Achievements
- Designed and implemented a unified monocular perception pipeline
- Integrated object tracking, trajectory prediction, road segmentation, and depth estimation
- Optimized multi-task modules through shared Transformer backbones and lightweight decoders
- Achieved real-time performance suitable for autonomous driving applications

## Technologies Used
- **Deep Learning**: PyTorch, Transformer architectures
- **Computer Vision**: Object detection, depth estimation, semantic segmentation
- **Optimization**: Multi-task learning, shared representations
- **Performance**: GPU optimization for real-time inference

## Publication
Currently under review at IEEE Robotics and Automation Letters (RA-L).

---